{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6445d802",
   "metadata": {},
   "source": [
    "# Understanding the P-Value\n",
    "\n",
    "The **P-value** (Probability Value) is a number between 0 and 1 that quantifies the evidence against the Null Hypothesis ($H_0$). \n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Formal Definition\n",
    "The P-value is the probability of obtaining test results **at least as extreme** as the results actually observed, under the assumption that the **Null Hypothesis is true**.\n",
    "\n",
    "* **It is NOT:** The probability that the Null Hypothesis is true.\n",
    "* **It is NOT:** The probability that the data occurred by chance.\n",
    "* **It is:** A measure of how \"surprising\" your data is if we assume nothing actually happened.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Decision Rule (The Alpha Threshold)\n",
    "To make a decision, we compare the P-value to a pre-defined significance level, **Alpha ($\\alpha$)**, which is usually set to **0.05**.\n",
    "\n",
    "| P-value Result | Interpretation | Action |\n",
    "| :--- | :--- | :--- |\n",
    "| **$P \\le 0.05$** | Strong evidence against $H_0$. | **Reject $H_0$** (Significant) |\n",
    "| **$P > 0.05$** | Weak evidence against $H_0$. | **Fail to Reject $H_0$** (Not Significant) |\n",
    "\n",
    "> **Mnemonic:** *\"If the P is low, the Null must go. If the P is high, the Null can fly.\"*\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Interpreting P-values in Data Science\n",
    "\n",
    "In a real-world context, a P-value tells you about the **reliability of an effect**:\n",
    "\n",
    "* **P = 0.001:** Highly significant. It is very unlikely you would see this result by pure luck.\n",
    "* **P = 0.045:** Statistically significant, but \"borderline.\" You should be cautious and perhaps check your sample size.\n",
    "* **P = 0.350:** Not significant. The difference you observed is likely just random noise in the data.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Drawbacks and Misuse (P-Hacking)\n",
    "P-values have limitations that every Data Scientist must know:\n",
    "1. **Sample Size Sensitivity:** With a large enough sample ($n = 1,000,000$), even tiny, meaningless differences can become \"statistically significant\" (low P-value).\n",
    "2. **No Measure of Effect Size:** A P-value tells you *if* there is an effect, but it doesn't tell you *how big* or *important* that effect is.\n",
    "3. **P-Hacking:** This occurs when researchers run many tests and only report the ones with P < 0.05, leading to false discoveries.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python: Calculating P-value Manually\n",
    "This script shows how a Z-score is converted into a P-value using the Cumulative Distribution Function (CDF).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55df5127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 2.15\n",
      "P-value: 0.0316\n",
      "Conclusion: Statistically Significant (Reject H0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Assume we calculated a Z-score of 2.15 from our data\n",
    "z_score = 2.15\n",
    "\n",
    "# 2. Calculate the P-value for a two-tailed test\n",
    "# We find the area in the tail and multiply by 2\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "print(f\"Z-score: {z_score}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# 3. Decision Logic\n",
    "alpha = 0.05\n",
    "if p_value <= alpha:\n",
    "    print(\"Conclusion: Statistically Significant (Reject H0)\")\n",
    "else:\n",
    "    print(\"Conclusion: Not Significant (Fail to Reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef2d0f",
   "metadata": {},
   "source": [
    "# Understanding the P-Value: The \"Surprise Meter\"\n",
    "\n",
    "The **P-value** (Probability Value) is the most critical metric in hypothesis testing. It quantifies the evidence against the Null Hypothesis ($H_0$).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Simple Example: The \"Magic\" Coin\n",
    "Imagine your friend claims to have a \"magic\" coin that always lands on **Heads**. You want to test if the coin is actually fair.\n",
    "\n",
    "* **Null Hypothesis ($H_0$):** The coin is fair (50% Heads).\n",
    "* **Alternative Hypothesis ($H_a$):** The coin is biased (Heads > 50%).\n",
    "\n",
    "### The Experiment\n",
    "You flip the coin 5 times. The P-value measures how \"surprised\" you should be by the results **if the coin were actually fair**.\n",
    "\n",
    "| Result | Observation | Surprise Level | P-Value |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **1 Head** | Perfectly normal. | Not surprised. | **P = 0.50** |\n",
    "| **3 Heads** | Very common. | Still not surprised. | **P = 0.31** |\n",
    "| **4 Heads** | A bit unusual. | Slightly suspicious. | **P = 0.15** |\n",
    "| **5 Heads** | **Very rare!** | **Highly Surprised!** | **P = 0.03** |\n",
    "\n",
    "\n",
    "\n",
    "**Conclusion:** Since the P-value for 5 heads (0.03) is less than 0.05, you reject the idea that the coin is fair. It is likely biased.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Formal Definition\n",
    "The P-value is the probability of obtaining test results **at least as extreme** as the ones observed, assuming the **Null Hypothesis is true**.\n",
    "\n",
    "* **Low P-value ($\\le 0.05$):** The data is very unlikely if the Null is true $\\rightarrow$ **Reject the Null.**\n",
    "* **High P-value ($> 0.05$):** The data is consistent with random chance $\\rightarrow$ **Fail to Reject the Null.**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The Courtroom Analogy\n",
    "Think of a P-value like a criminal trial:\n",
    "\n",
    "1.  **The Assumption ($H_0$):** The defendant is **Innocent**.\n",
    "2.  **The Evidence:** Fingerprints, DNA, and security footage.\n",
    "3.  **The P-Value:** The probability that we would find all this incriminating evidence if the person were actually innocent.\n",
    "4.  **The Verdict:** If that probability is near zero, the evidence is so strong that we **Reject the Assumption of Innocence** and find them **Guilty**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Summary: How to Read the \"Surprise Meter\"\n",
    "\n",
    "| P-Value Range | Meaning in Plain English | Decision |\n",
    "| :--- | :--- | :--- |\n",
    "| **$P > 0.10$** | \"This happens all the time by accident.\" | Keep the Null ($H_0$) |\n",
    "| **$0.05 < P < 0.10$** | \"A bit unusual, but could still be luck.\" | Keep the Null ($H_0$) |\n",
    "| **$P \\le 0.05$** | \"There is no way this is just luck!\" | **Reject the Null ($H_0$)** |\n",
    "| **$P \\le 0.01$** | \"This result is almost impossible by luck.\" | **Strongly Reject $H_0$** |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python: Calculating P-value for a Mean\n",
    "This script calculates the P-value to see if a sample of 30 people have a significantly different IQ than the population average (100).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58636cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 2.9212\n",
      "P-value: 0.0035\n",
      "Decision: Reject H0 (Significant Result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Sample Data\n",
    "sample_mean = 108\n",
    "pop_mean = 100\n",
    "pop_std = 15\n",
    "n = 30\n",
    "\n",
    "# 2. Calculate Z-score\n",
    "z_score = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
    "\n",
    "# 3. Calculate Two-Tailed P-value\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "print(f\"Z-score: {z_score:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Decision: Reject H0 (Significant Result)\")\n",
    "else:\n",
    "    print(\"Decision: Fail to Reject H0 (Not Significant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd630739",
   "metadata": {},
   "source": [
    "# The P-Value Approach to Hypothesis Testing\n",
    "\n",
    "The **P-value approach** is a method of testing a hypothesis by comparing the probability of obtaining your sample data to a pre-set threshold called **Alpha ($\\alpha$)**. \n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Core Logic\n",
    "In this approach, we don't look at \"cutoff lines\" on a graph first. Instead, we calculate exactly how likely our data is if the **Null Hypothesis ($H_0$)** were true.\n",
    "\n",
    "* **Small P-value:** The data is very unlikely under $H_0$. We conclude that something significant is happening.\n",
    "* **Large P-value:** The data is common under $H_0$. We conclude the result is just random noise.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The 4-Step Process\n",
    "\n",
    "1.  **State Hypotheses:** Define your $H_0$ (no effect) and $H_a$ (effect exists).\n",
    "2.  **Set Alpha ($\\alpha$):** Choose your significance level (Standard is $0.05$).\n",
    "3.  **Calculate the P-value:** * First, find your test statistic (Z or T).\n",
    "    * Then, find the area in the tail(s) of the distribution corresponding to that statistic.\n",
    "4.  **Make the Decision:**\n",
    "    * If **$P \\le \\alpha$**: Reject $H_0$ (Significant).\n",
    "    * If **$P > \\alpha$**: Fail to Reject $H_0$ (Not Significant).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Interpreting the \"Strength\" of Evidence\n",
    "One of the biggest advantages of this approach is that it provides a **gradient of evidence** rather than a simple \"Yes/No.\"\n",
    "\n",
    "| P-Value | Strength of Evidence against $H_0$ |\n",
    "| :--- | :--- |\n",
    "| **$P > 0.10$** | No evidence; purely random. |\n",
    "| **$0.05 < P \\le 0.10$** | Weak evidence; \"marginally significant.\" |\n",
    "| **$0.01 < P \\le 0.05$** | Moderate evidence; statistically significant. |\n",
    "| **$P \\le 0.01$** | Strong evidence; highly significant. |\n",
    "| **$P \\le 0.001$** | Very strong evidence. |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Advantages vs. Disadvantages\n",
    "\n",
    "### Advantages\n",
    "* **Nuance:** It tells you *how* significant a result is (a P-value of 0.0001 is much more convincing than 0.049).\n",
    "* **Software Friendly:** Almost all Python libraries (`scipy`, `statsmodels`, `sklearn`) output P-values automatically.\n",
    "* **Comparability:** It allows researchers to compare results across different experiments easily.\n",
    "\n",
    "### Disadvantages\n",
    "* **Misinterpretation:** People often mistake it for the \"probability that the Null is true\" (it is not).\n",
    "* **P-hacking:** It can lead to \"fishing\" for significant results by tweaking parameters until the P-value drops below 0.05.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python Example: P-Value Approach\n",
    "Using `scipy` to compare two groups of data (Independent T-test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63c1719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value: 0.00017\n",
      "Result is Significant (P=0.00017 <= 0.05). Reject H0.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Sample Data (e.g., test scores from two different classes)\n",
    "class_A = [85, 88, 90, 92, 85, 89, 91]\n",
    "class_B = [78, 82, 85, 80, 81, 79, 83]\n",
    "\n",
    "# 2. Set Alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# 3. Calculate P-Value (using ttest_ind)\n",
    "t_stat, p_value = stats.ttest_ind(class_A, class_B)\n",
    "\n",
    "print(f\"P-Value: {p_value:.5f}\")\n",
    "\n",
    "# 4. Make Decision\n",
    "if p_value <= alpha:\n",
    "    print(f\"Result is Significant (P={p_value:.5f} <= {alpha}). Reject H0.\")\n",
    "else:\n",
    "    print(f\"Result is Not Significant (P={p_value:.5f} > {alpha}). Fail to Reject H0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01c51e",
   "metadata": {},
   "source": [
    "# Comparison: P-Value vs. Rejection Region Approach\n",
    "\n",
    "Both methods are used to determine if a sample result is \"extreme\" enough to reject the Null Hypothesis. They differ in **what** they compare and **how** they visualize the data.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Core Difference\n",
    "\n",
    "| Feature | P-Value Approach | Rejection Region Approach |\n",
    "| :--- | :--- | :--- |\n",
    "| **Metric Used** | Probability (Area) | Test Statistic (Distance) |\n",
    "| **Compared Against** | Significance Level ($\\alpha$) | Critical Value ($Z_c$ or $t_c$) |\n",
    "| **Decision Rule** | Reject if $P \\le \\alpha$ | Reject if $|Stat| > |Critical Value|$ |\n",
    "| **Best For** | Modern Software / Data Science | Manual calculation / Statistical Tables |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Visual Comparison\n",
    "\n",
    "### The Rejection Region Approach (Horizontal Axis)\n",
    "In this approach, you mark a \"line in the sand\" on the horizontal axis called the **Critical Value**. If your calculated Z or T score crosses that line into the \"tail,\" you reject $H_0$.\n",
    "\n",
    "\n",
    "\n",
    "### The P-Value Approach (Area under the Curve)\n",
    "In this approach, you calculate the total area (probability) of the tail starting from your test statistic. If that area is smaller than the area of your significance level ($\\alpha$), you reject $H_0$.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Advantages and Disadvantages\n",
    "\n",
    "### P-Value Approach\n",
    "* **Pros:** Provides a measure of \"strength.\" A $P=0.0001$ is a much stronger rejection than $P=0.049$. It is the standard output for Python libraries like `scipy` and `statsmodels`.\n",
    "* **Cons:** Often misinterpreted as \"the probability that the Null is true\" (it is NOT).\n",
    "\n",
    "### Rejection Region Approach\n",
    "* **Pros:** Excellent for understanding the \"boundaries\" of a test. It clearly shows the threshold for a \"False Positive\" (Type I Error).\n",
    "* **Cons:** Binary result (Yes/No). It doesn't tell you if you *barely* rejected the null or rejected it by a *massive* margin.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Summary Table of Decisions\n",
    "\n",
    "To reach a conclusion of **\"Statistically Significant\"**, the following must be true:\n",
    "\n",
    "| Approach | Criteria for Rejection |\n",
    "| :--- | :--- |\n",
    "| **P-Value** | $P \\le \\alpha$ |\n",
    "| **Z-Test (Two-Tailed)** | $|Z_{calculated}| > Z_{critical}$ |\n",
    "| **T-Test (Two-Tailed)** | $|t_{calculated}| > t_{critical}$ |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python Demo: Both Approaches\n",
    "This script performs a test and shows that both methods yield the same conclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36b3a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Statistic: 1.8257 vs Critical Value: 1.9600\n",
      "P-Value: 0.0679 vs Alpha: 0.05\n",
      "Reject H0 (RR Method)? False\n",
      "Reject H0 (P-Value Method)? False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.05\n",
    "n = 30\n",
    "sample_mean = 105\n",
    "pop_mean = 100\n",
    "pop_std = 15\n",
    "\n",
    "# 1. Calculate Test Statistic (Z)\n",
    "z_stat = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
    "\n",
    "# 2. Rejection Region Method\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "reject_rr = abs(z_stat) > z_critical\n",
    "\n",
    "# 3. P-Value Method\n",
    "p_val = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "reject_p = p_val <= alpha\n",
    "\n",
    "print(f\"Z-Statistic: {z_stat:.4f} vs Critical Value: {z_critical:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f} vs Alpha: {alpha}\")\n",
    "print(f\"Reject H0 (RR Method)? {reject_rr}\")\n",
    "print(f\"Reject H0 (P-Value Method)? {reject_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb521482",
   "metadata": {},
   "source": [
    "# Understanding the T-Test\n",
    "\n",
    "The T-test compares the means of two groups and tells you if they are different from each other. It also tells you how significant the differences are; in other words, it lets you know if those differences could have happened by chance.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. When to use a T-test vs. Z-test?\n",
    "\n",
    "| Feature | T-test | Z-test |\n",
    "| :--- | :--- | :--- |\n",
    "| **Sample Size** | Small ($n < 30$) | Large ($n \\ge 30$) |\n",
    "| **Population Variance ($\\sigma^2$)** | Unknown | Known |\n",
    "| **Distribution** | T-distribution (fatter tails) | Normal distribution |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Types of T-tests\n",
    "\n",
    "Depending on your data structure, you will choose one of three main types:\n",
    "\n",
    "### A. One-Sample T-test\n",
    "Tests the mean of a single group against a known standard or theoretical mean.\n",
    "* **Example:** Checking if the average weight of a cereal box is really 500g.\n",
    "\n",
    "### B. Independent Two-Sample T-test (Unpaired)\n",
    "Compares the means of two independent groups to see if there is evidence that the associated population means are significantly different.\n",
    "* **Example:** Comparing the test scores of students in Class A vs. Class B.\n",
    "\n",
    "### C. Paired Sample T-test (Dependent)\n",
    "Compares means from the same group at different times or under different conditions.\n",
    "* **Example:** Measuring the weight of participants before and after a 30-day diet.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The T-test Formula (Independent Samples)\n",
    "\n",
    "The T-score is a ratio between the difference between two groups and the difference within the groups:\n",
    "\n",
    "$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\n",
    "\n",
    "* **Numerator:** The difference between sample means (Signal).\n",
    "* **Denominator:** The variation/error in the data (Noise).\n",
    "* **Result:** A large T-score indicates the groups are different; a small T-score indicates the groups are similar.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Key Assumptions\n",
    "Before running a T-test, your data should meet these criteria:\n",
    "1. **Independence:** Observations in one group are independent of observations in the other.\n",
    "2. **Normality:** The data should be approximately normally distributed.\n",
    "3. **Homogeneity of Variance:** The variance (spread) should be similar across groups (Levene’s test can check this).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python Example: Independent T-test\n",
    "Using `scipy.stats` to compare the heights of two different groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511de53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 3.1201\n",
      "P-value: 0.0089\n",
      "Conclusion: Significant difference between groups.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Generate Sample Data\n",
    "group_red = [170, 172, 180, 165, 175, 178, 182]\n",
    "group_blue = [160, 162, 170, 155, 165, 168, 172]\n",
    "\n",
    "# 2. Run Independent T-test\n",
    "t_stat, p_val = stats.ttest_ind(group_red, group_blue)\n",
    "\n",
    "# 3. Output Results\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_val:.4f}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Conclusion: Significant difference between groups.\")\n",
    "else:\n",
    "    print(\"Conclusion: No significant difference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b82ecd",
   "metadata": {},
   "source": [
    "# The One-Sample T-Test\n",
    "\n",
    "The One-Sample T-test tells us whether our sample comes from a specific population or if the sample mean significantly deviates from a \"standard\" value.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. When to Use It\n",
    "* You have **one group** of numerical data.\n",
    "* You want to compare the average of that group to a **fixed value** (a \"test value\").\n",
    "* The population standard deviation ($\\sigma$) is **unknown**.\n",
    "* The data follows a roughly normal distribution.\n",
    "\n",
    "**Example Scenario:** A manufacturer claims that a bag of chips weighs exactly **200 grams**. You collect a sample of 20 bags and find the average weight is **196 grams**. You use a One-Sample T-test to see if that 4g difference is a real discrepancy or just random variation.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Hypotheses\n",
    "* **Null Hypothesis ($H_0$):** $\\mu = \\mu_0$  \n",
    "  *(The sample mean is equal to the test value; there is no significant difference.)*\n",
    "* **Alternative Hypothesis ($H_a$):** $\\mu \\neq \\mu_0$ (Two-tailed), $\\mu > \\mu_0$, or $\\mu < \\mu_0$ (One-tailed).  \n",
    "  *(The sample mean is significantly different from the test value.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The Formula\n",
    "The T-statistic is calculated as:\n",
    "\n",
    "$$t = \\frac{\\bar{x} - \\mu}{s / \\sqrt{n}}$$\n",
    "\n",
    "Where:\n",
    "* $\\bar{x}$ = Sample Mean\n",
    "* $\\mu$ = Hypothesized Population Mean (Test Value)\n",
    "* $s$ = Sample Standard Deviation\n",
    "* $n$ = Sample Size\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Key Assumption: Degrees of Freedom ($df$)\n",
    "The T-test depends on the sample size. The \"Degrees of Freedom\" determines the shape of the T-distribution curve.\n",
    "* **Formula:** $df = n - 1$\n",
    "* As $df$ increases, the T-distribution looks more like a standard Normal (Z) Distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python Implementation\n",
    "Using `scipy.stats.ttest_1samp` to test a dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac75fe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 197.7\n",
      "T-statistic: -2.9132\n",
      "P-value: 0.0172\n",
      "Conclusion: Reject H0. The bags are significantly lighter than claimed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Our sample data (weights of 10 chip bags)\n",
    "sample_weights = [198, 202, 195, 197, 199, 196, 201, 194, 198, 197]\n",
    "\n",
    "# 2. The value we are testing against (Company claim)\n",
    "claimed_mean = 200\n",
    "\n",
    "# 3. Perform One-Sample T-test\n",
    "t_stat, p_val = stats.ttest_1samp(sample_weights, claimed_mean)\n",
    "\n",
    "print(f\"Sample Mean: {np.mean(sample_weights)}\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_val:.4f}\")\n",
    "\n",
    "# 4. Conclusion\n",
    "alpha = 0.05\n",
    "if p_val < alpha:\n",
    "    print(\"Conclusion: Reject H0. The bags are significantly lighter than claimed.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to Reject H0. The difference is not significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f50de2",
   "metadata": {},
   "source": [
    "# Independent Two-Sample T-Test\n",
    "\n",
    "The Independent T-test is the gold standard for **A/B Testing**. It helps you decide if a difference in averages between two groups (like Group A and Group B) is \"real\" or just a result of random chance.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. When to Use It\n",
    "* You have **two separate groups** (e.g., Treatment vs. Control, Men vs. Women, Android vs. iOS).\n",
    "* The data in each group is **numerical** (e.g., revenue, height, test scores).\n",
    "* A person or item can only belong to **one** of the two groups.\n",
    "* You want to know if the average of Group 1 is different from the average of Group 2.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Hypotheses\n",
    "* **Null Hypothesis ($H_0$):** $\\mu_1 = \\mu_2$  \n",
    "  *(There is no difference between the two group means.)*\n",
    "* **Alternative Hypothesis ($H_a$):** $\\mu_1 \\neq \\mu_2$ (Two-tailed) or $\\mu_1 > \\mu_2$ (One-tailed).  \n",
    "  *(There is a significant difference between the means.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The Formula\n",
    "The T-statistic calculates the \"Signal-to-Noise\" ratio:\n",
    "\n",
    "$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\n",
    "\n",
    "* **Numerator ($\\bar{x}_1 - \\bar{x}_2$):** The difference between the two sample means (The \"Signal\").\n",
    "* **Denominator:** The pooled standard error (The \"Noise\" or variation in the data).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Key Assumptions\n",
    "To trust your results, the data must meet these criteria:\n",
    "1. **Independence:** The observations in Group 1 must be independent of Group 2.\n",
    "2. **Normality:** The data in both groups should follow a normal distribution (especially for small samples).\n",
    "3. **Homogeneity of Variance:** The spread (variance) of the two groups should be roughly equal. If they are very different, we use **Welch’s T-test** instead.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python Implementation\n",
    "Using `scipy.stats.ttest_ind` to compare two website layouts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf5bf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean A: 47.25 | Mean B: 60.38\n",
      "T-statistic: -5.8762\n",
      "P-value: 0.0000\n",
      "Conclusion: Reject H0. Layout B is significantly different/better.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Group A: Seconds spent on Website Layout A\n",
    "layout_a = [45, 52, 38, 47, 50, 42, 55, 49]\n",
    "\n",
    "# 2. Group B: Seconds spent on Website Layout B\n",
    "layout_b = [60, 58, 65, 55, 62, 59, 61, 63]\n",
    "\n",
    "# 3. Perform Independent T-test\n",
    "# By default, this assumes equal variance. \n",
    "# Use equal_var=False for Welch's T-test if variances differ.\n",
    "t_stat, p_val = stats.ttest_ind(layout_a, layout_b)\n",
    "\n",
    "print(f\"Mean A: {np.mean(layout_a):.2f} | Mean B: {np.mean(layout_b):.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_val:.4f}\")\n",
    "\n",
    "# 4. Decision\n",
    "if p_val < 0.05:\n",
    "    print(\"Conclusion: Reject H0. Layout B is significantly different/better.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to Reject H0. No significant difference found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a3e93",
   "metadata": {},
   "source": [
    "# Paired Sample T-Test (Dependent)\n",
    "\n",
    "The Paired T-test focuses on the **difference** between two related observations. By testing the same subjects twice, you remove \"individual noise\" (like personality or genetics), making the test very powerful.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. When to Use It\n",
    "* **Before and After:** Measuring a variable on the same subject before and after an intervention (e.g., weight before and after a diet).\n",
    "* **Repeated Measures:** Testing the same subject under two different conditions (e.g., reaction time with caffeine vs. without).\n",
    "* **Matched Pairs:** Testing two different people who are \"twins\" in every other way (e.g., a study on pairs of identical twins).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Hypotheses\n",
    "In a paired test, we are actually testing the **mean of the differences ($d$)**.\n",
    "* **Null Hypothesis ($H_0$):** $\\mu_d = 0$  \n",
    "  *(The average difference between the pairs is zero; the treatment had no effect.)*\n",
    "* **Alternative Hypothesis ($H_a$):** $\\mu_d \\neq 0$  \n",
    "  *(There is a significant average difference between the pairs.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 3. How It Works (The Formula)\n",
    "The test essentially turns two columns of data into one column of \"Differences\" and performs a One-Sample T-test on those differences.\n",
    "\n",
    "$$t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}$$\n",
    "\n",
    "Where:\n",
    "* $\\bar{d}$ = The mean of the differences between the pairs.\n",
    "* $s_d$ = The standard deviation of those differences.\n",
    "* $n$ = The number of pairs.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Advantages\n",
    "* **High Statistical Power:** Because you are comparing the same person to themselves, you don't have to worry about \"between-subject\" variance. \n",
    "* **Smaller Sample Sizes:** You can often find significant results with fewer participants than an independent test would require.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Python Implementation\n",
    "Using `scipy.stats.ttest_rel` (where 'rel' stands for related).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f27a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Improvement: 4.62 points\n",
      "T-statistic: -11.0138\n",
      "P-value: 0.0000\n",
      "Conclusion: Reject H0. There is a significant improvement in scores.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Scores of 8 students before a training module\n",
    "pre_test = [72, 65, 80, 78, 60, 71, 85, 77]\n",
    "\n",
    "# 2. Scores of the SAME 8 students after the module\n",
    "post_test = [78, 70, 85, 80, 65, 75, 90, 82]\n",
    "\n",
    "# 3. Perform Paired T-test\n",
    "t_stat, p_val = stats.ttest_rel(pre_test, post_test)\n",
    "\n",
    "print(f\"Mean Improvement: {np.mean(post_test) - np.mean(pre_test):.2f} points\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_val:.4f}\")\n",
    "\n",
    "# 4. Decision\n",
    "if p_val < 0.05:\n",
    "    print(\"Conclusion: Reject H0. There is a significant improvement in scores.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to Reject H0. No significant change found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
